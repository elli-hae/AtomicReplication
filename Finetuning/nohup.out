Some weights of the model checkpoint at bert_weights_v3 were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert_weights_v3 and are newly initialized: ['bert.pooler.dense.bias', 'classifier.bias', 'classifier.weight', 'bert.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/haehnel/miniconda3/envs/py3.10/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
cpu
['promptID', 'pairID', 'premise', 'premise_binary_parse', 'premise_parse', 'hypothesis', 'hypothesis_binary_parse', 'hypothesis_parse', 'genre', 'label']
100000
9832
The model has 109,484,547 trainable parameters
Epoch 1: train_loss: 1.1084 train_acc: 0.3368 | val_loss: 1.0979 val_acc: 0.3521
32:10:21.70
Epoch 2: train_loss: 1.1039 train_acc: 0.3429 | val_loss: 1.0984 val_acc: 0.3524
32:49:50.04
Epoch 3: train_loss: 1.1031 train_acc: 0.3412 | val_loss: 1.0994 val_acc: 0.3296
34:17:10.46
Epoch 4: train_loss: 1.1020 train_acc: 0.3426 | val_loss: 1.1002 val_acc: 0.3523
31:51:44.08
Epoch 5: train_loss: 1.1017 train_acc: 0.3411 | val_loss: 1.0999 val_acc: 0.3298
33:09:12.56
